
# [Algorithm Analysis & Design] Assignment
## Week - 7, Lecture - 1

## Dynamic Programming
 - Dynamic Programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using Dynamic Programming. 
 - DP algorithm solves each subproblem just once and then remembers its answer, thereby avoiding re-computation of the answer for similar subproblem every time.

### 1. Shortest Reliable Paths
- Suppose that we are given a graph G with the lengths on the endges, along with two nodes s and t and an integer k, and we want the shortest path from s to t that uses atmost k edges.

 If we represent the graph by an adjacency matrix W = (wij). Consider a shortest path p from vetrtex i and vertex j and suppose that p contains m edges.
``` bash
Let L(i, j)(m) be the mninimum weight of any path from vertex i to vertex j that contains atmost m edges.

When m = 0;
    L(i, j)(0) = 0   if (i == j)
    L(i, j)(0) = INF if (i != j)

For m >= 1, we compute L(i, j)(m) as 
    the minimum of L(i, j)(m - 1) (the weight of the shortest path from i to j consisting of atmost m  - 1 edges).
    and the minimum weight of any path from i to j consisting of atmost m edges, obtained by looking at all possivle predecessors k of j.

Thus we recursively define:
        L(i, j)(m) = min(L(i, j)(m - 1), min(L(i, k)(m - 1) + wkj)) where 1 <= k <= n
                   = min(L(i, k)(m - 1) + wkj)                      where 1 <= k <= n 
```
### 2. All Pairs Shortest Path: Floyd-Warshall Algorithm
 - The Floyd Warshall Algorithm is for solving the All Pairs Shortest Path problem. 
 - The problem is to find shortest distances between every pair of vertices in a given edge weighted directed Graph. 

#### Approach
``` bash
Let dist(i, j, k) denote the length of the shortest path from i to j in which only the nodes 
{1, 2, …, k} can be used as intermediates.​

for i = 1 to n:
    for j = 1 to n:
        dist(i, j, 0) = INT_MAX

for all (i, j) ∈ E
    dist(i, j, 0) = l(i, j)
for k = 1 to n:
    for i = 1 to n:
        for j = 1 to n:
            dist(i, j, k) = min{dist(i, k, k - 1) + dist(k, j, k - 1), dist(i, j, k - 1)}
```
```bash
void floyd-Warshall-Algorithm(int graph[V][V])
{
    for (i = 0; i < V; i++)
        for (j = 0; j < V; j++)
            dist[i][j] = graph[i][j];
 
    for (k = 0; k < V; k++) 
    {
        for (i = 0; i < V; i++) 
        {
            for (j = 0; j < V; j++) 
            {
                if (dist[i][j] > (dist[i][k] + dist[k][j]) && 
                    (dist[i][k] != INF && dist[k][j] != INF))
                        dist[i][j] = dist[i][k] + dist[k][j];
            }
        }
    }
}
```
#### Complexity Analysis : 
Time Complexity: O(|V|^3) 
 ### 3. Independent Set in Trees
A subset of all tree nodes is an independent set if there is no edge between any two nodes of the subset. 

Input: Given a Binary Tree.

Output: Find out the the size of the largest Independent Set In Trees(LIST) in it
#### Optimal Substructure
For every node X, either X is a member of the set/ not a member of the set.
    
- If X is a member: LIST(X) = 1 + LIST(all Graandchildren of X).
- If X is not a member: LIST(X) = LIST(all children of X).

#### 1. Algorithm1 (Recursive Approach) Pseudocode
``` bash 
int LIST(Node *root)
{
    if (root == NULL)
        return 0;
    
    int size_opt1 = 0, size_opt2 = 0;
    size_opt1 = LIST(root->left) + LIST(root->right);

    if (root->left != NULL) 
        size_opt2 += LIST(root->left->left) + LIST(root->left->right);
    if (root->right != NULL)
        size_opt2 += LIST(root->right->left) + LIST(root->right->right);
    
    int size = max(size_opt1, 1 + size_opt2);
    return size;
}
```
#### Complexity Analysis : 
 - Time complexity of this recursive approach is exponential i.e. O(2^n).
 - Auxiliary Space : O(1)

 There are many subproblems in the above recursive solution which are solved again and again. So this problem has Overlapping Substructure property and recomputation of same subproblems can be avoided by either using Memoization or Tabulation.
#### 2. Algorithm 2 (Dynamic Programming) Approach
 We can use Memoization which is an extension to recursive approach so that we can overcome the problem of considering the redundant cases and hance increased time complexity.
 
 We can use unordered_map that can store the elements formed by the combination of Node * of Binary Tree and ize of the largest Independent Set In Trees with root X i.e. a mapped value. #### Pseudocode
``` bash
int LIST(Node *root, unordered_map<Node*, int> listMap)
{
    if (root == NULL)
        return 0;
        
    if (listMap.find(root) != listMap.end())
        return map[root];

    int size_opt1 = 0, size_opt2 = 0;
    size_opt1 = LIST(root->left) + LIST(root->right);

    if (root->left != NULL) 
        size_opt2 += LIST(root->left->left) + LIST(root->left->right);
    if (root->right != NULL)
        size_opt2 += LIST(root->right->left) + LIST(root->right->right);
    
    int size = max(size_opt1, 1 + size_opt2);
    listMap[root] = size;
    return listMap[root];
}
```
#### Complexity Analysis : 
 - Time complexity : O(N), wheere N is the number of nodes present in the Binary Tree.
